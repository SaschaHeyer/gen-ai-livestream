{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HayZwm7VAYe"
      },
      "source": [
        "# Vertex AI Batch Prediction\n",
        "\n",
        "This is the **third** part of a series. I recommend to check out the previous articles as prerequisite for this part.\n",
        "\n",
        "1. [Train Machine Learning models with Vertex AI Training](https://medium.com/google-cloud/how-to-train-ml-models-with-vertex-ai-training-f9046bfbcfab)\n",
        "2. [Serving Machine Learning models with Google Vertex AI](https://medium.com/google-cloud/serving-machine-learning-models-with-google-vertex-ai-5d9644ededa3)\n",
        "3. [Article](https://medium.com/google-cloud/google-vertex-ai-batch-predictions-ad7057d18d1f)\n",
        "\n",
        "\n",
        "Your feedback and questions are highly appreciated. <br>You can find me on Twitter [@HeyerSascha](https://twitter.com/HeyerSascha) or connect with me via [LinkedIn](https://www.linkedin.com/in/saschaheyer/). <br>Even better, subscribe to my [YouTube](https://www.youtube.com/channel/UC--Sm3D-rqCUeLXmraypdPQ) channel ❤️."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authentication and Dependencies"
      ],
      "metadata": {
        "id": "_qu1pYosDmdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmHHZZQEVBmM"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oHvleLfVCom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6c6ee7-277c-46d3-8ab5-d24a74e6ef8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "! gcloud config set project sascha-playground-doit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk2abD_bXaoe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "outputId": "80ce80b5-a0ea-4fad-abb5-e8a3d5f6e24d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-aiplatform==1.26.0\n",
            "  Downloading google_cloud_aiplatform-1.26.0-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.26.0) (2.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.26.0) (1.22.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.26.0) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.26.0) (23.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.26.0) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform==1.26.0) (3.9.0)\n",
            "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform==1.26.0)\n",
            "  Downloading google_cloud_resource_manager-1.10.1-py2.py3-none-any.whl (321 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.3/321.3 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shapely<2.0.0 (from google-cloud-aiplatform==1.26.0)\n",
            "  Downloading Shapely-1.8.5.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (2.27.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (1.54.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (1.48.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.26.0) (2.3.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.26.0) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.26.0) (2.8.2)\n",
            "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.26.0)\n",
            "  Downloading grpc_google_iam_v1-0.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.26.0) (1.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.26.0) (0.5.0)\n",
            "Installing collected packages: shapely, grpc-google-iam-v1, google-cloud-resource-manager, google-cloud-aiplatform\n",
            "  Attempting uninstall: shapely\n",
            "    Found existing installation: shapely 2.0.1\n",
            "    Uninstalling shapely-2.0.1:\n",
            "      Successfully uninstalled shapely-2.0.1\n",
            "Successfully installed google-cloud-aiplatform-1.26.0 google-cloud-resource-manager-1.10.1 grpc-google-iam-v1-0.12.6 shapely-1.8.5.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install google-cloud-aiplatform==1.26.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init SDK"
      ],
      "metadata": {
        "id": "viFI5VuGDpX-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry4ARzQ4XXDY"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkEmIRVIA-z2"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project='sascha-playground-doit')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBuOjWSLVDJ5"
      },
      "source": [
        "## Upload model\n",
        "\n",
        "If you want to know how the container-image (prediction container) was created check out my previous article: </br>[Serving Machine Learning models with Google Vertex AI](https://medium.com/google-cloud/serving-machine-learning-models-with-google-vertex-ai-5d9644ededa3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bCoxllfZo67"
      },
      "source": [
        "### gcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-Rk_yvoVm9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dab36bb3-c554-4c52-a5c6-1ed82cd7d347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n"
          ]
        }
      ],
      "source": [
        "!gcloud ai models upload \\\n",
        "  --container-ports=80 \\\n",
        "  --container-predict-route=\"/predict\" \\\n",
        "  --container-health-route=\"/health\" \\\n",
        "  --region=us-central1 \\\n",
        "  --display-name=sentiment-batch-example \\\n",
        "  --container-image-uri=gcr.io/sascha-playground-doit/sentiment-fast-api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HOxCDDd-nA4"
      },
      "source": [
        "### SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9OEYjMS-KkV"
      },
      "outputs": [],
      "source": [
        " model = aiplatform.Model.upload(\n",
        "        display_name=\"sentiment-batch-example\",\n",
        "        serving_container_image_uri=\"gcr.io/sascha-playground-doit/sentiment-fast-api\",\n",
        "        serving_container_predict_route=\"/predict\",\n",
        "        serving_container_health_route=\"/health\",\n",
        "        serving_container_ports=[80]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhT1lKzi-oPx"
      },
      "source": [
        "## Reference the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeZMSPYcVz7V"
      },
      "outputs": [],
      "source": [
        "#you can use the following code to create a reference to a model if the model is already uploaded\n",
        "model = aiplatform.Model('projects/sascha-playground-doit/locations/us-central1/models/5347349457363009536')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Batch Prediction / Cloud Storage"
      ],
      "metadata": {
        "id": "UUrdgxi7DzTS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdnxFG_5ZG_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "df6315fa-ca41-4b57-908f-b08795029cd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating BatchPredictionJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchPredictionJob created. Resource name: projects/234439745674/locations/us-central1/batchPredictionJobs/5331795628437536768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob created. Resource name: projects/234439745674/locations/us-central1/batchPredictionJobs/5331795628437536768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To use this BatchPredictionJob in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:To use this BatchPredictionJob in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bpj = aiplatform.BatchPredictionJob('projects/234439745674/locations/us-central1/batchPredictionJobs/5331795628437536768')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/234439745674/locations/us-central1/batchPredictionJobs/5331795628437536768')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View Batch Prediction Job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/5331795628437536768?project=234439745674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:View Batch Prediction Job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/5331795628437536768?project=234439745674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/5331795628437536768 current state:\n",
            "JobState.JOB_STATE_PENDING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/5331795628437536768 current state:\n",
            "JobState.JOB_STATE_PENDING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/5331795628437536768 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/5331795628437536768 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-90e658883c88>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m batch_prediction_job = model.batch_predict(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minstances_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jsonl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m    \u001b[0mjob_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"batch_predict_sentiment\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgcs_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gs://doit-vertex-demo/batch/input/batch-key-2.jsonl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgcs_destination_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gs://doit-vertex-demo/batch/output'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mbatch_predict\u001b[0;34m(self, job_display_name, gcs_source, bigquery_source, instances_format, gcs_destination_prefix, bigquery_destination_prefix, predictions_format, model_parameters, machine_type, accelerator_type, accelerator_count, starting_replica_count, max_replica_count, generate_explanation, explanation_metadata, explanation_parameters, labels, credentials, encryption_spec_key_name, sync, create_request_timeout, batch_size, service_account)\u001b[0m\n\u001b[1;32m   3732\u001b[0m         \"\"\"\n\u001b[1;32m   3733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3734\u001b[0;31m         return jobs.BatchPredictionJob.create(\n\u001b[0m\u001b[1;32m   3735\u001b[0m             \u001b[0mjob_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_display_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3736\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, job_display_name, model_name, instances_format, predictions_format, gcs_source, bigquery_source, gcs_destination_prefix, bigquery_destination_prefix, model_parameters, machine_type, accelerator_type, accelerator_count, starting_replica_count, max_replica_count, generate_explanation, explanation_metadata, explanation_parameters, labels, project, location, credentials, encryption_spec_key_name, sync, create_request_timeout, batch_size, model_monitoring_objective_config, model_monitoring_alert_config, analysis_instance_schema_uri, service_account)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;31m# TODO(b/242108750): remove temporary logic once model monitoring for batch prediction is GA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         return cls._create(\n\u001b[0m\u001b[1;32m    795\u001b[0m             \u001b[0mempty_batch_prediction_job\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_batch_prediction_job\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mmodel_or_model_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, empty_batch_prediction_job, model_or_model_name, gca_batch_prediction_job, generate_explanation, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    873\u001b[0m         )\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0mbatch_prediction_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_prediction_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mlog_wait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_wait\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_WAIT_TIME_MULTIPLIER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MAX_WAIT_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mprevious_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_JOB_WAIT_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_job_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "batch_prediction_job = model.batch_predict(\n",
        "    instances_format='jsonl',\n",
        "   job_display_name=f\"batch_predict_sentiment\",\n",
        "    gcs_source=['gs://doit-vertex-demo/batch/input/batch-key-2.jsonl'],\n",
        "    gcs_destination_prefix='gs://doit-vertex-demo/batch/output',\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    starting_replica_count=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Batch Prediction / BigQuery"
      ],
      "metadata": {
        "id": "DH0rnqZpD7Yt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "65f09kmlbmqf",
        "outputId": "0df2b616-7f4e-491f-9c4a-4c5964635aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating BatchPredictionJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchPredictionJob created. Resource name: projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob created. Resource name: projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To use this BatchPredictionJob in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:To use this BatchPredictionJob in another session:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bpj = aiplatform.BatchPredictionJob('projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View Batch Prediction Job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/8770293943934910464?project=234439745674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:View Batch Prediction Job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/8770293943934910464?project=234439745674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/234439745674/locations/us-central1/batchPredictionJobs/8770293943934910464 current state:\n",
            "JobState.JOB_STATE_RUNNING\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-61c15536de88>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m batch_prediction_job = model.batch_predict(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mjob_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"batch_predict_sentiment\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmachine_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"n1-standard-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstarting_replica_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mbatch_predict\u001b[0;34m(self, job_display_name, gcs_source, bigquery_source, instances_format, gcs_destination_prefix, bigquery_destination_prefix, predictions_format, model_parameters, machine_type, accelerator_type, accelerator_count, starting_replica_count, max_replica_count, generate_explanation, explanation_metadata, explanation_parameters, labels, credentials, encryption_spec_key_name, sync, create_request_timeout, batch_size, service_account)\u001b[0m\n\u001b[1;32m   3732\u001b[0m         \"\"\"\n\u001b[1;32m   3733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3734\u001b[0;31m         return jobs.BatchPredictionJob.create(\n\u001b[0m\u001b[1;32m   3735\u001b[0m             \u001b[0mjob_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_display_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3736\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, job_display_name, model_name, instances_format, predictions_format, gcs_source, bigquery_source, gcs_destination_prefix, bigquery_destination_prefix, model_parameters, machine_type, accelerator_type, accelerator_count, starting_replica_count, max_replica_count, generate_explanation, explanation_metadata, explanation_parameters, labels, project, location, credentials, encryption_spec_key_name, sync, create_request_timeout, batch_size, model_monitoring_objective_config, model_monitoring_alert_config, analysis_instance_schema_uri, service_account)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;31m# TODO(b/242108750): remove temporary logic once model monitoring for batch prediction is GA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         return cls._create(\n\u001b[0m\u001b[1;32m    795\u001b[0m             \u001b[0mempty_batch_prediction_job\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_batch_prediction_job\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mmodel_or_model_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, empty_batch_prediction_job, model_or_model_name, gca_batch_prediction_job, generate_explanation, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    873\u001b[0m         )\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0mbatch_prediction_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_prediction_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mlog_wait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_wait\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_WAIT_TIME_MULTIPLIER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MAX_WAIT_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0mprevious_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_JOB_WAIT_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_job_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "batch_prediction_job = model.batch_predict(\n",
        "    job_display_name=f\"batch_predict_sentiment\",\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    starting_replica_count=2,\n",
        "\n",
        "    instances_format=\"bigquery\",\n",
        "    predictions_format=\"bigquery\",\n",
        "    bigquery_source='bq://sascha-playground-doit.batch.data',\n",
        "    bigquery_destination_prefix=\"bq://sascha-playground-doit.batch\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W2K4KjGanLO"
      },
      "source": [
        "## IMDB Dataset preprocessing (dataset used in this notebook)\n",
        "Using the test dataset to run the batch prediction on.\n",
        "\n",
        "https://ai.stanford.edu/~amaas/data/sentiment/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaIBXwONaw_e"
      },
      "outputs": [],
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thkrIkO8a3Ng"
      },
      "outputs": [],
      "source": [
        "!tar -xvf \"/content/aclImdb_v1.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuVlQh_gbxJh"
      },
      "outputs": [],
      "source": [
        "!pip install jsonlines==3.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZnbpYEEa9ww"
      },
      "outputs": [],
      "source": [
        "import jsonlines\n",
        "import os\n",
        "import csv\n",
        "\n",
        "sentences = []\n",
        "sentences_raw = []\n",
        "\n",
        "index = 0\n",
        "\n",
        "path = '/content/aclImdb/test/neg'\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith(\"txt\"):\n",
        "\n",
        "      with open(path + '/' + filename, \"r\") as file:\n",
        "        text = file.read()\n",
        "        sentence = {\"text\":text, \"key\": index, \"test\": \"test\"}\n",
        "        sentences.append(sentence)\n",
        "        sentences_raw.append(str(text))\n",
        "        index = index + 1\n",
        "\n",
        "path = '/content/aclImdb/test/pos'\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith(\"txt\"):\n",
        "\n",
        "      with open(path + '/' + filename, \"r\") as file:\n",
        "        text = file.read()\n",
        "        sentence = {\"text\":text, \"key\": index, \"test\": \"test\"}\n",
        "        sentences.append(sentence)\n",
        "        sentences_raw.append(str(text))\n",
        "        index = index + 1\n",
        "\n",
        "with jsonlines.open('batch-key-2.jsonl', 'w') as writer:\n",
        "      writer.write_all(sentences)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUVJxRU-Qio1"
      },
      "outputs": [],
      "source": [
        "print(sentences_raw[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jYyM2_5JUSyX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}