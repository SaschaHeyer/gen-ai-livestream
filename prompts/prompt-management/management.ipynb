{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Management with Vertex AI\n",
    "\n",
    "This notebook demonstrates how to create, manage, and use prompt templates with Vertex AI's prompt management features. Prompt management allows you to version, share, and reuse prompts across your organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Vertex AI\n",
    "\n",
    "First, we set up the project ID and location, then initialize the Vertex AI client to access Vertex AI services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wn84vMusWOQR"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"sascha-playground-doit\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries\n",
    "\n",
    "We import the necessary modules from the Vertex AI SDK, including the prompts modules that allow us to create and manage prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lVO9O6zWOSf"
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview import prompts\n",
    "from vertexai.preview.prompts import Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a Local Prompt Template\n",
    "\n",
    "Here we create a local prompt template for artist name matching. This template includes:\n",
    "- A prompt name for identification\n",
    "- The main prompt text with a variable placeholder {artist}\n",
    "- Example variables to substitute into the prompt\n",
    "- The Gemini model to use\n",
    "- A detailed system instruction that guides the model's behavior\n",
    "\n",
    "Note that this prompt remains local until we explicitly save it to Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJtYYdc5Zz_x"
   },
   "outputs": [],
   "source": [
    "# this prompt is local until saved\n",
    "prompt = Prompt(\n",
    "    prompt_name=\"artist-matcher\",\n",
    "    prompt_data=\"correct the following artist {artist}\",\n",
    "    variables=[\n",
    "        {\"artist\": \"acdc\"},\n",
    "        {\"artist\": \"Pink Floy\"},\n",
    "    ],\n",
    "    model_name=\"gemini-2.0-flash-001\",\n",
    "    system_instruction=\"\"\"\n",
    "    you are a artist matching services based on a list of artists provided you suggest the correct naming. users might use slightly different names you need to ensure they are exactly as in the artist list\n",
    "\n",
    "    artists:\n",
    "    The Rolling Stones\n",
    "    The Beatles\n",
    "    Led Zeppelin\n",
    "    Pink Floyd\n",
    "    The Who\n",
    "    The Doors\n",
    "    Queen\n",
    "    Aerosmith\n",
    "    The Eagles\n",
    "    Fleetwood Mac\n",
    "    David Bowie\n",
    "    Jimi Hendrix\n",
    "    Bob Dylan\n",
    "    AC/DC\n",
    "    Guns N' Roses\n",
    "    The Clash\n",
    "    Nirvana\n",
    "    U2\n",
    "    Bruce Springsteen\n",
    "    The Kinks\n",
    "    The Beach Boys\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save the Prompt to Vertex AI\n",
    "\n",
    "We now save the local prompt to Vertex AI's prompt management system using the create_version() function. This creates a persistent, versioned prompt resource in Vertex AI that can be shared and reused. The function returns a new Prompt object associated with the online resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Et_srrfXgp1",
    "outputId": "03cbe2c4-0980-4e75-d352-d3022009f2cb"
   },
   "outputs": [],
   "source": [
    "# Save a version\n",
    "prompt = prompts.create_version(prompt=prompt)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieving a Saved Prompt\n",
    "\n",
    "To access a prompt that was previously saved, we can use the get() method with the prompt ID. This allows you to retrieve prompt templates created by you or shared within your organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53Ppbe4DXXZ4",
    "outputId": "9feca78d-6e7f-4cb3-fca1-af4a7822c94a"
   },
   "outputs": [],
   "source": [
    "prompt = prompts.get(\"8464170802747539456\")  #prompt id from UI\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Listing All Available Prompts\n",
    "\n",
    "The list() method helps you discover all prompt templates available in your project. This is useful for finding existing prompts that you or your team have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVFi8H3ea8mM",
    "outputId": "ccfd081c-0c90-4f3d-9240-336db0aa10a7"
   },
   "outputs": [],
   "source": [
    "prompts.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using a Prompt with the Gemini Model\n",
    "\n",
    "Now we use our saved prompt to generate content with Gemini. We can either pass a direct input or use the prompt's variables. The system instructions we defined earlier guide the model to correct artist names according to our reference list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vu0__bwMZteB",
    "outputId": "93b408bb-254c-428d-e3d3-d53ad2c274ca"
   },
   "outputs": [],
   "source": [
    "\n",
    "response = prompt.generate_content(\n",
    "    \"acdc\"\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response.candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Updating an Existing Prompt\n",
    "\n",
    "To update a prompt, you modify its properties locally and then create a new version with create_version(). This preserves the version history while adding the updated version as the latest one. Here we change the system instruction and save a new version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KDnV63bbQAo"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate content using the assembled prompt (a prompt without variables)\n",
    "prompt.generate_content(\n",
    "  contents=prompt.assemble_contents()\n",
    ")\n",
    "\n",
    "# Update prompt (changes are local until create_version is called)\n",
    "prompt.system_instruction = \"new system instruction\"\n",
    "\n",
    "# Save Prompt to online resource. Since the prompt is associated with a prompt resource, it creates a new version under the same prompt_id. Returns a new Prompt object associated with the online resource\n",
    "prompts.create_version(prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Listing Prompt Versions\n",
    "\n",
    "Vertex AI maintains version history for each prompt. You can list all versions of a prompt using the list_versions() method, which returns metadata about each version including its ID and creation timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CprcdKprbCBD",
    "outputId": "c3c791f0-8605-4d11-b2b8-20dbef5b98aa"
   },
   "outputs": [],
   "source": [
    "prompt_versions = prompts.list_versions(prompt_id=\"4657221742735917056\")\n",
    "prompt_versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Retrieving a Specific Prompt Version\n",
    "\n",
    "You can retrieve a specific version of a prompt by providing both the prompt ID and version ID. This allows you to use older versions if needed or compare different versions of the same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a specific prompt version from the versions metadata list\n",
    "prompt1 = prompts.get(\n",
    "    prompt_id=prompt_versions[2].prompt_id,\n",
    "    version_id=prompt_versions[2].version_id\n",
    ")\n",
    "prompt1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
