{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Prompt Management with Vertex AI\n\nThis notebook demonstrates how to create, manage, and use prompt templates with Vertex AI's prompt management features. Prompt management allows you to version, share, and reuse prompts across your organization.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Initialize Vertex AI\n\nFirst, we set up the project ID and location, then initialize the Vertex AI client to access Vertex AI services.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wn84vMusWOQR"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"sascha-playground-doit\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "import vertexai\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Import Required Libraries\n\nWe import the necessary modules from the Vertex AI SDK, including the prompts modules that allow us to create and manage prompt templates.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lVO9O6zWOSf"
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview import prompts\n",
    "from vertexai.preview.prompts import Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Create a Local Prompt Template\n\nHere we create a local prompt template for artist name matching. This template includes:\n- A prompt name for identification\n- The main prompt text with a variable placeholder {artist}\n- Example variables to substitute into the prompt\n- The Gemini model to use\n- A detailed system instruction that guides the model's behavior\n\nNote that this prompt remains local until we explicitly save it to Vertex AI.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hJtYYdc5Zz_x"
   },
   "outputs": [],
   "source": [
    "# this prompt is local until saved\n",
    "prompt = Prompt(\n",
    "    prompt_name=\"artist-matcher\",\n",
    "    prompt_data=\"correct the following artist {artist}\",\n",
    "    variables=[\n",
    "        {\"artist\": \"acdc\"},\n",
    "        {\"artist\": \"Pink Floy\"},\n",
    "    ],\n",
    "    model_name=\"gemini-2.0-flash-001\",\n",
    "    system_instruction=\"\"\"\n",
    "    you are a artist matching services based on a list of artists provided you suggest the correct naming. users might use slightly different names you need to ensure they are exactly as in the artist list\n",
    "\n",
    "    artists:\n",
    "    The Rolling Stones\n",
    "    The Beatles\n",
    "    Led Zeppelin\n",
    "    Pink Floyd\n",
    "    The Who\n",
    "    The Doors\n",
    "    Queen\n",
    "    Aerosmith\n",
    "    The Eagles\n",
    "    Fleetwood Mac\n",
    "    David Bowie\n",
    "    Jimi Hendrix\n",
    "    Bob Dylan\n",
    "    AC/DC\n",
    "    Guns N' Roses\n",
    "    The Clash\n",
    "    Nirvana\n",
    "    U2\n",
    "    Bruce Springsteen\n",
    "    The Kinks\n",
    "    The Beach Boys\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Save the Prompt to Vertex AI\n\nWe now save the local prompt to Vertex AI's prompt management system using the create_version() function. This creates a persistent, versioned prompt resource in Vertex AI that can be shared and reused. The function returns a new Prompt object associated with the online resource.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Et_srrfXgp1",
    "outputId": "03cbe2c4-0980-4e75-d352-d3022009f2cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created prompt resource with id 8464170802747539456 with version number 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prompt(prompt_data='correct the following artist {artist}', variables=[{'artist': [text: \"acdc\"\n",
       "]}, {'artist': [text: \"Pink Floy\"\n",
       "]}]), system_instruction=\n",
       "    you are a artist matching services based on a list of artists provided you suggest the correct naming. users might use slightly different names you need to ensure they are exactly as in the artist list\n",
       "\n",
       "    artists:\n",
       "    The Rolling Stones\n",
       "    The Beatles\n",
       "    Led Zeppelin\n",
       "    Pink Floyd\n",
       "    The Who\n",
       "    The Doors\n",
       "    Queen\n",
       "    Aerosmith\n",
       "    The Eagles\n",
       "    Fleetwood Mac\n",
       "    David Bowie\n",
       "    Jimi Hendrix\n",
       "    Bob Dylan\n",
       "    AC/DC\n",
       "    Guns N' Roses\n",
       "    The Clash\n",
       "    Nirvana\n",
       "    U2\n",
       "    Bruce Springsteen\n",
       "    The Kinks\n",
       "    The Beach Boys\n",
       "    ), model_name=projects/sascha-playground-doit/locations/us-central1/publishers/google/models/gemini-2.0-flash-001), prompt_id=8464170802747539456, version_id=1, version_name=artist-matcher_2025_04_28_105055)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save a version\n",
    "prompt = prompts.create_version(prompt=prompt)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Retrieving a Saved Prompt\n\nTo access a prompt that was previously saved, we can use the get() method with the prompt ID. This allows you to retrieve prompt templates created by you or shared within your organization.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53Ppbe4DXXZ4",
    "outputId": "9feca78d-6e7f-4cb3-fca1-af4a7822c94a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prompt(prompt_data='correct the following artist {artist}', variables=[{'artist': [text: \"acdc\"\n",
       "]}, {'artist': [text: \"Pink Floy\"\n",
       "]}]), system_instruction=\n",
       "    you are a artist matching services based on a list of artists provided you suggest the correct naming. users might use slightly different names you need to ensure they are exactly as in the artist list\n",
       "\n",
       "    artists:\n",
       "    The Rolling Stones\n",
       "    The Beatles\n",
       "    Led Zeppelin\n",
       "    Pink Floyd\n",
       "    The Who\n",
       "    The Doors\n",
       "    Queen\n",
       "    Aerosmith\n",
       "    The Eagles\n",
       "    Fleetwood Mac\n",
       "    David Bowie\n",
       "    Jimi Hendrix\n",
       "    Bob Dylan\n",
       "    AC/DC\n",
       "    Guns N' Roses\n",
       "    The Clash\n",
       "    Nirvana\n",
       "    U2\n",
       "    Bruce Springsteen\n",
       "    The Kinks\n",
       "    The Beach Boys\n",
       "    ), model_name=projects/sascha-playground-doit/locations/us-central1/publishers/google/models/gemini-2.0-flash-001), prompt_id=8464170802747539456)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompts.get(\"8464170802747539456\")  #prompt id from UI\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Listing All Available Prompts\n\nThe list() method helps you discover all prompt templates available in your project. This is useful for finding existing prompts that you or your team have created.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVFi8H3ea8mM",
    "outputId": "ccfd081c-0c90-4f3d-9240-336db0aa10a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PromptMetadata(display_name='artist-matcher', prompt_id='8464170802747539456'),\n",
       " PromptMetadata(display_name='artist-matcher', prompt_id='4657221742735917056'),\n",
       " PromptMetadata(display_name='artist-matcher', prompt_id='89727295652102144'),\n",
       " PromptMetadata(display_name='artist-matcher', prompt_id='1715526761132851200'),\n",
       " PromptMetadata(display_name='artist-matcher', prompt_id='6854978360892719104'),\n",
       " PromptMetadata(display_name='movie-critic', prompt_id='4040228593786159104'),\n",
       " PromptMetadata(display_name='artist-matcher', prompt_id='2243292342465331200'),\n",
       " PromptMetadata(display_name='artist-matcher', prompt_id='8975329360454090752'),\n",
       " PromptMetadata(display_name='autocorrect_artists', prompt_id='446991608865357824'),\n",
       " PromptMetadata(display_name='untitled_1741956330206', prompt_id='8811339400194555904'),\n",
       " PromptMetadata(display_name='tlf_curn', prompt_id='2899837123689447424'),\n",
       " PromptMetadata(display_name='untitled_1741608550232', prompt_id='7829871340776587264'),\n",
       " PromptMetadata(display_name='untitled_1733387972446', prompt_id='6750839216579543040'),\n",
       " PromptMetadata(display_name='podcast optimized', prompt_id='2577268999402291200'),\n",
       " PromptMetadata(display_name='importtest', prompt_id='364009267293847552'),\n",
       " PromptMetadata(display_name='nextory-multi-vector', prompt_id='2649955514091307008'),\n",
       " PromptMetadata(display_name='untitled_1728383586306', prompt_id='8193543607756521472'),\n",
       " PromptMetadata(display_name='shelf face counting', prompt_id='1150195265525776384'),\n",
       " PromptMetadata(display_name='podcast-automation', prompt_id='10555861382463488'),\n",
       " PromptMetadata(display_name='Natural', prompt_id='4992099999207653376'),\n",
       " PromptMetadata(display_name='test', prompt_id='7518125159685816320'),\n",
       " PromptMetadata(display_name='egw', prompt_id='1108596892356313088'),\n",
       " PromptMetadata(display_name='HC-topics-extraction1', prompt_id='5724153191713472512'),\n",
       " PromptMetadata(display_name='HC sentiment', prompt_id='9220987196134129664'),\n",
       " PromptMetadata(display_name='HC 3 unstructured to structured', prompt_id='549306113632239616'),\n",
       " PromptMetadata(display_name='Yaron', prompt_id='952435454886543360'),\n",
       " PromptMetadata(display_name='stock', prompt_id='5245698507863490560'),\n",
       " PromptMetadata(display_name='hackathon_1', prompt_id='8110937848917524480'),\n",
       " PromptMetadata(display_name='213281_only_svg', prompt_id='4651557608585428992'),\n",
       " PromptMetadata(display_name='213281_4_even_smaller', prompt_id='6902794472317255680'),\n",
       " PromptMetadata(display_name='213281_3_smaller_parts', prompt_id='8990212899603480576'),\n",
       " PromptMetadata(display_name='213281_2', prompt_id='8938421503888719872'),\n",
       " PromptMetadata(display_name='213281', prompt_id='2584405379622371328'),\n",
       " PromptMetadata(display_name='RecSys 1 - next item ', prompt_id='9110160822100819968'),\n",
       " PromptMetadata(display_name='chart-distribution', prompt_id='3714496624790077440'),\n",
       " PromptMetadata(display_name='bank spendings', prompt_id='452315993922863104'),\n",
       " PromptMetadata(display_name='completion done?', prompt_id='1330922541539131392'),\n",
       " PromptMetadata(display_name='section generator', prompt_id='1250209591967350784'),\n",
       " PromptMetadata(display_name='generate novel', prompt_id='76670045316448256'),\n",
       " PromptMetadata(display_name='Untitled prompt', prompt_id='4282258041094537216'),\n",
       " PromptMetadata(display_name='Untitled prompt', prompt_id='7347766828078202880'),\n",
       " PromptMetadata(display_name='expose generierung', prompt_id='1269871058895241216'),\n",
       " PromptMetadata(display_name='detect chicken', prompt_id='6929620357011734528'),\n",
       " PromptMetadata(display_name='order video', prompt_id='7364921408494764032'),\n",
       " PromptMetadata(display_name='burger', prompt_id='3592312295641841664'),\n",
       " PromptMetadata(display_name='invoice-gemini', prompt_id='1691054381077626880'),\n",
       " PromptMetadata(display_name='classify tickets for routing', prompt_id='5885875958996533248'),\n",
       " PromptMetadata(display_name='use case 4 - help ticket classification', prompt_id='201066591859769344'),\n",
       " PromptMetadata(display_name='use case 3 - HR interview questions', prompt_id='2518168600141889536'),\n",
       " PromptMetadata(display_name='use case 2 - legal', prompt_id='4824011609355583488'),\n",
       " PromptMetadata(display_name='use case 1 - PII', prompt_id='8336819318704570368'),\n",
       " PromptMetadata(display_name='ticket-classification', prompt_id='6149037470034952192'),\n",
       " PromptMetadata(display_name='sentiment', prompt_id='4834197485075300352'),\n",
       " PromptMetadata(display_name='exctract_gemini', prompt_id='6624224405327183872'),\n",
       " PromptMetadata(display_name='gemini-bounding-box', prompt_id='3649315376472260608'),\n",
       " PromptMetadata(display_name='atlas', prompt_id='8085572115664732160'),\n",
       " PromptMetadata(display_name='ticket summarizatino', prompt_id='7418370867744210944'),\n",
       " PromptMetadata(display_name='ticket sum 3', prompt_id='7868730830481260544'),\n",
       " PromptMetadata(display_name='ticklet sum2', prompt_id='3764262720086474752'),\n",
       " PromptMetadata(display_name='unittest', prompt_id='5006262258729222144'),\n",
       " PromptMetadata(display_name='prompt-injection-1', prompt_id='1701021453983416320'),\n",
       " PromptMetadata(display_name='prompt-injection-2', prompt_id='2787514864086548480'),\n",
       " PromptMetadata(display_name='prompt injection 1', prompt_id='8438969446483099648'),\n",
       " PromptMetadata(display_name='recipe', prompt_id='7011926498932162560'),\n",
       " PromptMetadata(display_name='1 - football bullet point summary with sections', prompt_id='6220418864421797888'),\n",
       " PromptMetadata(display_name='2 - football short summary', prompt_id='5829168646793986048'),\n",
       " PromptMetadata(display_name='3 - football recommendation', prompt_id='8548779871772344320'),\n",
       " PromptMetadata(display_name='sms worker questionary', prompt_id='8355758406493011968'),\n",
       " PromptMetadata(display_name='test_v1', prompt_id='6898017094294568960'),\n",
       " PromptMetadata(display_name='support chat', prompt_id='2168815273090482176'),\n",
       " PromptMetadata(display_name='recipe', prompt_id='5112480579530522624'),\n",
       " PromptMetadata(display_name='issue1', prompt_id='1050796665595756544'),\n",
       " PromptMetadata(display_name='what can you do fail', prompt_id='3821636336335454208'),\n",
       " PromptMetadata(display_name='ensuring format and structure better', prompt_id='7050998744136810496'),\n",
       " PromptMetadata(display_name='ensuring format and structure issue', prompt_id='5563684967197704192'),\n",
       " PromptMetadata(display_name='json enforcing', prompt_id='5870809351161118720'),\n",
       " PromptMetadata(display_name='reducing model errors correct', prompt_id='7704407718198509568'),\n",
       " PromptMetadata(display_name='reducing model errors wrong', prompt_id='3600995138966388736'),\n",
       " PromptMetadata(display_name='few-shot', prompt_id='2194992445924573184'),\n",
       " PromptMetadata(display_name='bias correct', prompt_id='600190412254085120'),\n",
       " PromptMetadata(display_name='bias wrong', prompt_id='33862759112245248'),\n",
       " PromptMetadata(display_name='redact PII information', prompt_id='3992878675291799552'),\n",
       " PromptMetadata(display_name='product description', prompt_id='8164337830143721472'),\n",
       " PromptMetadata(display_name='clv', prompt_id='2120177276724183040'),\n",
       " PromptMetadata(display_name='cast-quality-inspection', prompt_id='6670301639112392704'),\n",
       " PromptMetadata(display_name='chihuahua-muffin', prompt_id='7216644568907776000'),\n",
       " PromptMetadata(display_name='higgs-demo-december', prompt_id='5017564138751131648'),\n",
       " PromptMetadata(display_name='demo-1', prompt_id='6859043805136420864'),\n",
       " PromptMetadata(display_name='loan', prompt_id='3674734985794813952'),\n",
       " PromptMetadata(display_name='higgs-boson-ai-campus', prompt_id='3081385734888751104'),\n",
       " PromptMetadata(display_name='higgs_boson', prompt_id='467397994921066496')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Using a Prompt with the Gemini Model\n\nNow we use our saved prompt to generate content with Gemini. We can either pass a direct input or use the prompt's variables. The system instructions we defined earlier guide the model to correct artist names according to our reference list.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vu0__bwMZteB",
    "outputId": "93b408bb-254c-428d-e3d3-d53ad2c274ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"AC/DC\\n\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  avg_logprobs: -2.7949688956141472e-05\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 137\n",
      "  candidates_token_count: 4\n",
      "  total_token_count: 141\n",
      "  prompt_tokens_details {\n",
      "    modality: TEXT\n",
      "    token_count: 137\n",
      "  }\n",
      "  candidates_tokens_details {\n",
      "    modality: TEXT\n",
      "    token_count: 4\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-001\"\n",
      "create_time {\n",
      "  seconds: 1745862775\n",
      "  nanos: 522189000\n",
      "}\n",
      "response_id: \"d8APaM3vH5yCm9IPqemeyQ4\"\n",
      "\n",
      "AC/DC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = prompt.generate_content(\n",
    "    \"acdc\"\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response.candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Updating an Existing Prompt\n\nTo update a prompt, you modify its properties locally and then create a new version with create_version(). This preserves the version history while adding the updated version as the latest one. Here we change the system instruction and save a new version.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KDnV63bbQAo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated prompt resource with id 4657221742735917056 as version number 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Generate content using the assembled prompt (a prompt without variables)\n",
    "prompt.generate_content(\n",
    "  contents=prompt.assemble_contents()\n",
    ")\n",
    "\n",
    "# Update prompt (changes are local until create_version is called)\n",
    "prompt.system_instruction = \"new system instruction\"\n",
    "\n",
    "# Save Prompt to online resource. Since the prompt is associated with a prompt resource, it creates a new version under the same prompt_id. Returns a new Prompt object associated with the online resource\n",
    "prompts.create_version(prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Listing Prompt Versions\n\nVertex AI maintains version history for each prompt. You can list all versions of a prompt using the list_versions() method, which returns metadata about each version including its ID and creation timestamp.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CprcdKprbCBD",
    "outputId": "c3c791f0-8605-4d11-b2b8-20dbef5b98aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PromptVersionMetadata(display_name='artist-matcher_2025_04_28_104430', prompt_id='4657221742735917056', version_id='1'),\n",
       " PromptVersionMetadata(display_name='artist-matcher_2025_04_28_104454', prompt_id='4657221742735917056', version_id='2'),\n",
       " PromptVersionMetadata(display_name='artist-matcher_2025_04_28_104756', prompt_id='4657221742735917056', version_id='3')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_versions = prompts.list_versions(prompt_id=\"4657221742735917056\")\n",
    "prompt_versions"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Retrieving a Specific Prompt Version\n\nYou can retrieve a specific version of a prompt by providing both the prompt ID and version ID. This allows you to use older versions if needed or compare different versions of the same prompt.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prompt(prompt_data='new prompt', variables=[{'artist': [text: \"acdc\"\n",
       "]}, {'artist': [text: \"Pink Floy\"\n",
       "]}]), system_instruction=new system instruction), model_name=projects/sascha-playground-doit/locations/us-central1/publishers/google/models/gemini-2.0-flash-001), prompt_id=4657221742735917056, version_id=3, version_name=artist-matcher_2025_04_28_104756)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a specific prompt version from the versions metadata list\n",
    "prompt1 = prompts.get(\n",
    "    prompt_id=prompt_versions[2].prompt_id,\n",
    "    version_id=prompt_versions[2].version_id\n",
    ")\n",
    "prompt1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}